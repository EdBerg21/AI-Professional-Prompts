{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 4966565,
          "sourceType": "datasetVersion",
          "datasetId": 2880535
        },
        {
          "sourceId": 5112,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 3900
        }
      ],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b84b3642b7745dc878731f8c6933272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f73fa823ff5c4f2d8b5dffe17f8a6275",
              "IPY_MODEL_9024ca41916045eb858c07dca70f396d",
              "IPY_MODEL_3b1204c622f746be80279443e648fafb"
            ],
            "layout": "IPY_MODEL_bba279e4d8cd4fe2a70b7b3d375ca7ed"
          }
        },
        "f73fa823ff5c4f2d8b5dffe17f8a6275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41dcd09e3bde44b0b04ea95ef9f326d6",
            "placeholder": "​",
            "style": "IPY_MODEL_cd322c55052c428fb57cc2c636412288",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9024ca41916045eb858c07dca70f396d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_122b1ca6f57e4a8583e1741102bb3378",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27deab876e7b4b88893c29f4b9f001d5",
            "value": 6
          }
        },
        "3b1204c622f746be80279443e648fafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79e54de2481d4891800c44eb7f9ce5e3",
            "placeholder": "​",
            "style": "IPY_MODEL_ec690ab6cb9e437a8be1493cef8dfbaf",
            "value": " 6/6 [04:42&lt;00:00, 42.37s/it]"
          }
        },
        "bba279e4d8cd4fe2a70b7b3d375ca7ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41dcd09e3bde44b0b04ea95ef9f326d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd322c55052c428fb57cc2c636412288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "122b1ca6f57e4a8583e1741102bb3378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27deab876e7b4b88893c29f4b9f001d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79e54de2481d4891800c44eb7f9ce5e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec690ab6cb9e437a8be1493cef8dfbaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdBerg21/AI-Professional-Prompts/blob/main/DONEJAIS_DONE_NATIONAL_UNIFIED_rag_with_mistral_7b_query_wikipedia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bitsandbytes is required for 4-bit quantization by transformers.AutoModelForCausalLM\n",
        "# sentence-transformers is required by model wrapper langchain.embeddings.HuggingFaceEmbeddings\n",
        "# faiss-gpu is required by embeddings db langchain.vectorstores.FAISS\n",
        "!pip install -q langchain bitsandbytes sentence-transformers faiss-gpu"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:09:09.964472Z",
          "iopub.execute_input": "2023-11-30T18:09:09.965118Z",
          "iopub.status.idle": "2023-11-30T18:09:41.629673Z",
          "shell.execute_reply.started": "2023-11-30T18:09:09.965084Z",
          "shell.execute_reply": "2023-11-30T18:09:41.628658Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuhrQ9-iX1Fl",
        "outputId": "5a5bf934-1cc7-4117-a536-de5f60de9759"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.0/798.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jH4S1Usdfh7",
        "outputId": "5d9d9c06-168d-41f0-ee42-f6476c0bd049"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->bitsandbytes) (1.23.5)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.42.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "import sys\n",
        "from timeit import default_timer\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import top_k_top_p_filtering\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema.document import Document"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:09:44.521838Z",
          "iopub.execute_input": "2023-11-30T18:09:44.522286Z",
          "iopub.status.idle": "2023-11-30T18:09:48.853117Z",
          "shell.execute_reply.started": "2023-11-30T18:09:44.522255Z",
          "shell.execute_reply": "2023-11-30T18:09:48.852326Z"
        },
        "trusted": true,
        "id": "-h4Ax90-X1Fy"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"core42/jais-13b\")\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"core42/jais-13b\",trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_URBEozHbKMs",
        "outputId": "4317411b-c4b1-4e1d-f280-e34f8fded241"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe28e1ea3b2dafad40747eafbe\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:09:48.855006Z",
          "iopub.execute_input": "2023-11-30T18:09:48.855595Z",
          "iopub.status.idle": "2023-11-30T18:09:48.860364Z",
          "shell.execute_reply.started": "2023-11-30T18:09:48.855567Z",
          "shell.execute_reply": "2023-11-30T18:09:48.859309Z"
        },
        "trusted": true,
        "id": "ZwrScejYX1F2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "## Files"
      ],
      "metadata": {
        "id": "WBrLSIxVX1F5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sizeof_fmt(num, suffix=\"B\"):\n",
        "    for unit in (\"\", \"Ki\", \"Mi\", \"Gi\", \"Ti\", \"Pi\", \"Ei\", \"Zi\"):\n",
        "        if abs(num) < 1024.0:\n",
        "            return f\"{num:5.1f} | {unit}{suffix}\"\n",
        "        num /= 1024.0\n",
        "    return f\"{num:.1f}Yi{suffix}\"\n",
        "\n",
        "path = Path(model_path)\n",
        "files = list(path.iterdir())\n",
        "files = sorted(files, key=lambda f: -f.stat().st_size)\n",
        "for file in files:\n",
        "    print(f'{file.as_posix() : <80.80}| {sizeof_fmt(file.stat().st_size)}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:09:48.861364Z",
          "iopub.execute_input": "2023-11-30T18:09:48.861593Z",
          "iopub.status.idle": "2023-11-30T18:09:50.603087Z",
          "shell.execute_reply.started": "2023-11-30T18:09:48.861572Z",
          "shell.execute_reply": "2023-11-30T18:09:50.602157Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6OCMXnaX1F-",
        "outputId": "03ea9a43-b509-4b69-ebbc-750d7de6d761"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe|   9.3 | GiB\n",
            "/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe|   9.3 | GiB\n",
            "/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe|   9.1 | GiB\n",
            "/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe|   9.1 | GiB\n",
            "/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe|   9.1 | GiB\n",
            "/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe|   4.2 | GiB\n",
            "/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe|   4.6 | MiB\n",
            "/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe|  67.0 | KiB\n",
            "/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe|  41.4 | KiB\n",
            "/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe|   6.6 | KiB\n",
            "/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe|   1.2 | KiB\n",
            "/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe| 215.0 | B\n",
            "/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe|  99.0 | B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer\n",
        "Load pretrained tokenizer."
      ],
      "metadata": {
        "id": "WieoZkDTX1GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:09:50.604765Z",
          "iopub.execute_input": "2023-11-30T18:09:50.605145Z",
          "iopub.status.idle": "2023-11-30T18:09:50.731119Z",
          "shell.execute_reply.started": "2023-11-30T18:09:50.60511Z",
          "shell.execute_reply": "2023-11-30T18:09:50.73035Z"
        },
        "trusted": true,
        "id": "wIZsra45X1GB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Y4XueEESX1GD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mistral Config"
      ],
      "metadata": {
        "id": "YPZImVPeX1GG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the config shows us we need to instantiate huggingface's AutoModelForCausalLM\n",
        "model_config = transformers.AutoConfig.from_pretrained(model_path)\n",
        "model_config"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:09:50.732256Z",
          "iopub.execute_input": "2023-11-30T18:09:50.732552Z",
          "iopub.status.idle": "2023-11-30T18:09:50.748338Z",
          "shell.execute_reply.started": "2023-11-30T18:09:50.732526Z",
          "shell.execute_reply": "2023-11-30T18:09:50.747492Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVQ3Ik8hX1GI",
        "outputId": "fabb109a-f0c7-4b77-ddb6-aa66b47d6bad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for /root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe28e1ea3b2dafad40747eafbe contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co//root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe28e1ea3b2dafad40747eafbe.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "JAISConfig {\n",
              "  \"_name_or_path\": \"/root/.cache/huggingface/hub/models--core42--jais-13b/snapshots/21d1e2a27e5f93fe28e1ea3b2dafad40747eafbe\",\n",
              "  \"activation_function\": \"swiglu\",\n",
              "  \"architectures\": [\n",
              "    \"JAISLMHeadModel\"\n",
              "  ],\n",
              "  \"attn_pdrop\": 0.0,\n",
              "  \"auto_map\": {\n",
              "    \"AutoConfig\": \"configuration_jais.JAISConfig\",\n",
              "    \"AutoModel\": \"modeling_jais.JAISModel\",\n",
              "    \"AutoModelForCausalLM\": \"modeling_jais.JAISLMHeadModel\",\n",
              "    \"AutoModelForQuestionAnswering\": \"modeling_jais.JAISForQuestionAnswering\",\n",
              "    \"AutoModelForSequenceClassification\": \"modeling_jais.JAISForSequenceClassification\",\n",
              "    \"AutoModelForTokenClassification\": \"modeling_jais.JAISForTokenClassification\"\n",
              "  },\n",
              "  \"bos_token_id\": 0,\n",
              "  \"embd_pdrop\": 0.0,\n",
              "  \"embeddings_scale\": 14.6,\n",
              "  \"eos_token_id\": 0,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"layer_norm_epsilon\": 1e-05,\n",
              "  \"model_type\": \"jais\",\n",
              "  \"n_embd\": 5120,\n",
              "  \"n_head\": 40,\n",
              "  \"n_inner\": 13653,\n",
              "  \"n_layer\": 40,\n",
              "  \"n_positions\": 2048,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"alibi\",\n",
              "  \"reorder_and_upcast_attn\": false,\n",
              "  \"resid_pdrop\": 0.0,\n",
              "  \"scale_attn_by_inverse_layer_idx\": false,\n",
              "  \"scale_attn_weights\": true,\n",
              "  \"scale_qk_dot_by_d\": true,\n",
              "  \"torch_dtype\": \"float32\",\n",
              "  \"transformers_version\": \"4.35.2\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 84992,\n",
              "  \"width_scale\": 0.11100000000000002\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-bit Quantization"
      ],
      "metadata": {
        "id": "wbg2Sdm4X1GK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>4-bit Quantization</b><br><br> Quantization in the context of deep learning is the process of constraining the number of bits that represent the weights and biases of the model - Weights and Biases numbers that we need in backpropagation. In 4-bit quantization, each weight or bias is represented using only 4 bits as opposed to the typical 32 bits used in single-precision floating-point format (float32). The primary advantage of using 4-bit quantization is the reduction in model size and memory usage. <br><br>\n",
        "\n",
        "See https://www.kaggle.com/code/lorentzyeung/what-s-4-bit-quantization-how-does-it-help-llama2\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "iPisz1AHX1GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# requires bitsandbytes package to be installed\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "  #  bnb_4bit_compute_dtype=bfloat16\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:09:50.749426Z",
          "iopub.execute_input": "2023-11-30T18:09:50.749769Z",
          "iopub.status.idle": "2023-11-30T18:09:50.758671Z",
          "shell.execute_reply.started": "2023-11-30T18:09:50.749734Z",
          "shell.execute_reply": "2023-11-30T18:09:50.757877Z"
        },
        "trusted": true,
        "id": "NR5COjZAX1GN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained Model"
      ],
      "metadata": {
        "id": "kFf0lFA-X1GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hIjOZXLjh_-",
        "outputId": "b978a57e-0423-4be2-a05c-bcfb7cb22537"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "XillPeqIjcY9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PytQGv_2iyho",
        "outputId": "0d2163ba-a8fa-49d6-ef14-76882c4821c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import accelerate"
      ],
      "metadata": {
        "id": "qZh2xG4vJXFz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t0 = default_timer()\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    trust_remote_code=True,\n",
        "    config=model_config,\n",
        "    quantization_config=bnb_config,\n",
        "    torch_dtype = torch.bfloat16,\n",
        "   # device_map=\"auto\",  # {\"\": 1},  # \"cuda:0\",\n",
        "     device_map='auto',\n",
        "     load_in_4bit=True\n",
        ")\n",
        "print(default_timer(), 'sec.')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:09:52.062747Z",
          "iopub.execute_input": "2023-11-30T18:09:52.063193Z",
          "iopub.status.idle": "2023-11-30T18:12:16.114132Z",
          "shell.execute_reply.started": "2023-11-30T18:09:52.063161Z",
          "shell.execute_reply": "2023-11-30T18:12:16.113105Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "0b84b3642b7745dc878731f8c6933272",
            "f73fa823ff5c4f2d8b5dffe17f8a6275",
            "9024ca41916045eb858c07dca70f396d",
            "3b1204c622f746be80279443e648fafb",
            "bba279e4d8cd4fe2a70b7b3d375ca7ed",
            "41dcd09e3bde44b0b04ea95ef9f326d6",
            "cd322c55052c428fb57cc2c636412288",
            "122b1ca6f57e4a8583e1741102bb3378",
            "27deab876e7b4b88893c29f4b9f001d5",
            "79e54de2481d4891800c44eb7f9ce5e3",
            "ec690ab6cb9e437a8be1493cef8dfbaf"
          ]
        },
        "id": "W6TE5KixX1GQ",
        "outputId": "633eb507-f769-4dba-802a-f976bcb335f3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b84b3642b7745dc878731f8c6933272"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2472.901132344 sec.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>Quantized Model</b><br><br> We currently can't save a model that has been quantized with BitsAndBytes <br><br>\n",
        "\n",
        "See Pull Request https://github.com/huggingface/transformers/pull/26037\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "MGdz_ffaX1GS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Architecture\\n')\n",
        "model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:12:16.116087Z",
          "iopub.execute_input": "2023-11-30T18:12:16.11639Z",
          "iopub.status.idle": "2023-11-30T18:12:16.126311Z",
          "shell.execute_reply.started": "2023-11-30T18:12:16.116364Z",
          "shell.execute_reply": "2023-11-30T18:12:16.125356Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLKyIZqFX1GU",
        "outputId": "89beee26-3afd-4986-ed50-7fa751cffa3f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "JAISLMHeadModel(\n",
              "  (transformer): JAISModel(\n",
              "    (wte): Embedding(84992, 5120)\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-39): 40 x JAISBlock(\n",
              "        (ln_1): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): JAISAttention(\n",
              "          (c_attn): Linear4bit(in_features=5120, out_features=15360, bias=True)\n",
              "          (c_proj): Linear4bit(in_features=5120, out_features=5120, bias=True)\n",
              "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): JAISMLP(\n",
              "          (c_fc): Linear4bit(in_features=5120, out_features=13653, bias=True)\n",
              "          (c_fc2): Linear4bit(in_features=5120, out_features=13653, bias=True)\n",
              "          (c_proj): Linear4bit(in_features=13653, out_features=5120, bias=True)\n",
              "          (act): SwiGLUActivation()\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
              "    (relative_pe): AlibiPositionEmbeddingLayer()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=5120, out_features=84992, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Model (without head) \\n\\n')\n",
        "model.model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:12:16.159381Z",
          "iopub.execute_input": "2023-11-30T18:12:16.159672Z",
          "iopub.status.idle": "2023-11-30T18:12:16.173026Z",
          "shell.execute_reply.started": "2023-11-30T18:12:16.159648Z",
          "shell.execute_reply": "2023-11-30T18:12:16.172042Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "uBQcbXihX1GZ",
        "outputId": "cd397b3e-a139-4073-8674-9cb7752cff86"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model (without head) \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-85671f219a08>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model (without head) \\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model"
      ],
      "metadata": {
        "id": "Nmquk65zX1Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.\"\n",
        "messages = [{\n",
        "    \"role\":\"user\",\n",
        "    \"content\": query\n",
        "}]\n",
        "model_inputs = tokenizer.apply_chat_template(messages, return_tensors = \"pt\").to('cuda')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:12:43.911468Z",
          "iopub.execute_input": "2023-11-30T18:12:43.911845Z",
          "iopub.status.idle": "2023-11-30T18:12:43.91807Z",
          "shell.execute_reply.started": "2023-11-30T18:12:43.911816Z",
          "shell.execute_reply": "2023-11-30T18:12:43.917029Z"
        },
        "trusted": true,
        "id": "qm74npARX1Gc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting `pad_token_id` to `eos_token_id` for open-ended generation.\n",
        "generated_ids = model.generate(\n",
        "    model_inputs,\n",
        "    max_new_tokens = 7500,\n",
        "    do_sample = True,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        ")\n",
        "print('Generated IDs:', generated_ids)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:12:47.86227Z",
          "iopub.execute_input": "2023-11-30T18:12:47.862644Z",
          "iopub.status.idle": "2023-11-30T18:12:55.425578Z",
          "shell.execute_reply.started": "2023-11-30T18:12:47.862611Z",
          "shell.execute_reply": "2023-11-30T18:12:55.424627Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGaBiwy3X1Ge",
        "outputId": "5ba46926-3295-487c-cb5c-5846281ba49d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:569: UserWarning: Some matrices hidden dimension is not a multiple of 64 and efficient inference kernels are not supported for these (slow). Matrix input size found: torch.Size([1, 1, 13653])\n",
            "  warn(f'Some matrices hidden dimension is not a multiple of {quant_state.blocksize} and efficient inference kernels are not supported for these (slow). Matrix input size found: {A.shape}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated IDs: tensor([[ 28,  92, 441,  ..., 820,   9,   0]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "print('Decoded:', decoded)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:12:55.427048Z",
          "iopub.execute_input": "2023-11-30T18:12:55.427346Z",
          "iopub.status.idle": "2023-11-30T18:12:55.43356Z",
          "shell.execute_reply.started": "2023-11-30T18:12:55.427321Z",
          "shell.execute_reply": "2023-11-30T18:12:55.432587Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SMWhOYQX1Gg",
        "outputId": "0850a35f-73d6-4813-c207-8aa0b5b137bd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded: ['<|im_start|>user\\nPlease explain what is the State of the Union address. Give just a definition. Keep it in 100 words.<|im_end|>\\n\\nThis one is really fun. The user enters a number. Then, all the words that start with that number, or that are one of the two numbers specified by the user\\'s entry are selected and printed.\\n\\n```scratch\\nmake a variable called \"thenumber\"\\nask for \"Enter a number from 1 to 5\" give it as an integer from the user.\\nchange the number in the \"thenumber\" variable to the one the user entered.\\nask a new question:\\n\"choose a 1 or a 2\"\\nchange the number from 1 to 2 in the \"thenumber\" variable to any of those the user chooses.\\nask:\\n\"now choose another number from 1 to 5\"\\nchange the number again from 1 to 5 in the \"thenumber\" variable, but this time to any the user chooses.\\nask:\\n\"choose another number from 1 to 5\"\\nchange the number to one of them from 1 to 5 in the \"thenumber\" variable again, but this time any the user chooses.\\nask this question:\\n\"and then another one from 1 to 5\"\\nchange the number to one of them from 1 to 5 in the \"thenumber\" variable, then any the user chooses.\\nask this question:\\n\"and then one more from 1 to 5\"\\nchange the number to one of them from 1 to 5 in the \"thenumber\" variable, then any the user chooses.\\nchange the number in the \"thenumber\" variable to any of the three the user chooses.\\nask this question:\\n\"what is the number you have chosen?\"<|im_start|> |thenumber|<|im_end|>\\n```\\n\\nFor example, if the user enters a number between one and five, the message will display all words that start with whatever number the user entered, and a new number for each question until the user chooses another number, then it will continue.\\n\\n```scratch\\n|reversed| reversed<|im_start|>\\nPlease give me the reversal of the following words:\\nPlease enter your words and then the one letter letter<|im_end|>\\n\\nPlease give me the reversal of a single \"a\"<|im_start|>\\nPlease enter your single letter word and then the one letter \"a\"<|im_end|>\\n\\n\\n```\\n\\n## If/else conditional statements\\n\\nScratch has a conditional logic if/else. For example, to test `if a > b` we can write the following:\\n\\n```scratch\\nif a > b<|im_start|>\\n     yes\\nelse\\n     no\\nelse \\n```\\n\\n\\n\\n\\n\\nIf we wanted the output to say \\'no\\' if a greater than b but not `else if` but the output to say `yes` if not, we would write the following:\\n\\n```scratch\\nif a > b<|im_start|>\\n     no\\n     else\\n         yes\\nelse\\n     no<|im_end|>\\n```\\n\\nIf we wanted to make the output `yes` in both cases, then we would do:\\n\\n```scratch\\nif a > b<|im_start|>\\n     yes\\nelse\\n     no\\n     else\\n         yes\\nelse\\n     no\\n     else\\n         yes<|im_end|>\\n```\\n\\n## Scratch variables\\n\\nWe\\'ve also noticed a `variablename := \\'value\\'` in the scratch code. What does this do?\\n\\nWe know when we add our variables and strings in the code, it can output the results. But also, if we have variables and they add together we need to replace the space to a `+` or it won\\'t display. We can change this through Scratch code.\\n\\nFor example, if we want to change this variable: `variablename := \\'value\\'`\\n\\nWe want to change it to: `number := \\'100\\'`\\n\\nWe could use a little bit of Scratch code `variablename => \\'value\\'`\\n\\nSo for example:\\n\\n```scratch\\nask for 100\\ngive it as a number from 10\\nmake a variable called \"number\"\\n|variablename => \\'value\\'|<|im_start|>number<|im_end|>\\n```\\n\\nNow it will print 100.\\n\\n# Scratch projects\\n\\n## Project 1: Draw a spiral\\n\\n## Project 2: Create a game\\n\\n## Project 3: Draw shapes\\n\\n## Project 4: Create a music box game\\n\\n## Project 5: Make a musical song\\n\\n## Project 6: Create a robot arm\\n\\n## Project 7: Create a storybook\\n\\n# Video tutorials and lessons\\n\\n## Coding basics\\n\\n## Creating a story\\n\\n## Coding a loop\\n\\n## Creating music loops\\n\\n## Making a program\\n\\n## Coding a story\\n\\n## Coding loops\\n\\n## Scratch community\\n\\n## Making programs\\n\\n## Working together\\n\\n## Creating your own group\\n\\n## Working with the community\\n\\n## Download Scratch\\n\\n## [Download Scratch 2](https://scratch.mit.edu/docs/en/getting_started/download/)\\n\\n## Getting help \\n\\n## [Getting help](https://scratch.mit.edu/docs/en/quick_start/users_guide)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG"
      ],
      "metadata": {
        "id": "Oz1ogs63X1Gi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/RAG_schema.svg/1024px-RAG_schema.svg.png)"
      ],
      "metadata": {
        "id": "dDi9zWjRX1Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap tokenizer and model with pipeline\n",
        "pipeline = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task='text-generation',\n",
        "    # temperature=0.1,\n",
        "    max_new_tokens=150,\n",
        "    # repetition_penalty=1.1\n",
        "    return_full_text=False,\n",
        "#     torch_dtype=torch.float16,\n",
        "    pad_token_id = tokenizer.eos_token_id,  # open-end generation (and suppressing warning...)\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:13:05.411381Z",
          "iopub.execute_input": "2023-11-30T18:13:05.412008Z",
          "iopub.status.idle": "2023-11-30T18:13:07.247501Z",
          "shell.execute_reply.started": "2023-11-30T18:13:05.411963Z",
          "shell.execute_reply": "2023-11-30T18:13:07.246722Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CVVZfWLX1Gk",
        "outputId": "e122b4b2-1a27-4721-fcf0-7a5ec6cf98b1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'JAISLMHeadModel' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap pipeline with langchain's HuggingFacePipeline\n",
        "llm = HuggingFacePipeline(pipeline=pipeline)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:13:07.248956Z",
          "iopub.execute_input": "2023-11-30T18:13:07.249223Z",
          "iopub.status.idle": "2023-11-30T18:13:07.25469Z",
          "shell.execute_reply.started": "2023-11-30T18:13:07.249199Z",
          "shell.execute_reply": "2023-11-30T18:13:07.253775Z"
        },
        "trusted": true,
        "id": "aO6le9PmX1Gm"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG - State of the Union 2023"
      ],
      "metadata": {
        "id": "TjfUZcP8X1Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader(\"/content/biden-sotu-2023-autogenerated-transcript.txt\",\n",
        "                    encoding=\"utf8\")\n",
        "documents = loader.load()\n",
        "print(len(documents), 'Document')\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
        "                                               chunk_overlap=20)\n",
        "all_splits = text_splitter.split_documents(documents)\n",
        "print(len(all_splits), 'Chunks')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:13:25.349432Z",
          "iopub.execute_input": "2023-11-30T18:13:25.349811Z",
          "iopub.status.idle": "2023-11-30T18:13:25.39032Z",
          "shell.execute_reply.started": "2023-11-30T18:13:25.349778Z",
          "shell.execute_reply": "2023-11-30T18:13:25.389448Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwI23Od9X1Gp",
        "outputId": "1e67ddad-d664-4997-a3cc-691c43d8f0b4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Document\n",
            "54 Chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "embeddings_model_kwargs = {\"device\": \"cuda\"}\n",
        "\n",
        "# HuggingFaceEmbeddings is a langchain class\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name,\n",
        "                                   model_kwargs=embeddings_model_kwargs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:13:27.026325Z",
          "iopub.execute_input": "2023-11-30T18:13:27.027206Z",
          "iopub.status.idle": "2023-11-30T18:13:33.836849Z",
          "shell.execute_reply.started": "2023-11-30T18:13:27.027171Z",
          "shell.execute_reply": "2023-11-30T18:13:33.835779Z"
        },
        "trusted": true,
        "id": "vRUFrsBYX1Gr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = FAISS.from_documents(all_splits, embeddings)\n",
        "retriever = db.as_retriever()  # langchain_core.vectorstores.VectorStoreRetriever"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:13:33.838582Z",
          "iopub.execute_input": "2023-11-30T18:13:33.839597Z",
          "iopub.status.idle": "2023-11-30T18:13:34.653809Z",
          "shell.execute_reply.started": "2023-11-30T18:13:33.839558Z",
          "shell.execute_reply": "2023-11-30T18:13:34.653088Z"
        },
        "trusted": true,
        "id": "cfbWGltWX1Gs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:13:39.29132Z",
          "iopub.execute_input": "2023-11-30T18:13:39.2917Z",
          "iopub.status.idle": "2023-11-30T18:13:39.297158Z",
          "shell.execute_reply.started": "2023-11-30T18:13:39.291666Z",
          "shell.execute_reply": "2023-11-30T18:13:39.296171Z"
        },
        "trusted": true,
        "id": "NjibmUClX1Gu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What were the main topics in the State of the Union in 2023? Summarize. Keep it under 200 words.\"\n",
        "print(f\"Query: {query}\\n\")\n",
        "result = qa.run(query)\n",
        "print(\"\\nResult: \", result)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:13:41.595433Z",
          "iopub.execute_input": "2023-11-30T18:13:41.59579Z",
          "iopub.status.idle": "2023-11-30T18:13:52.361368Z",
          "shell.execute_reply.started": "2023-11-30T18:13:41.595764Z",
          "shell.execute_reply": "2023-11-30T18:13:52.360375Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80hgQ2u4X1Gv",
        "outputId": "ff80d407-1c04-410e-98e8-b8e128d2e0e1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What were the main topics in the State of the Union in 2023? Summarize. Keep it under 200 words.\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:569: UserWarning: Some matrices hidden dimension is not a multiple of 64 and efficient inference kernels are not supported for these (slow). Matrix input size found: torch.Size([1, 1, 13653])\n",
            "  warn(f'Some matrices hidden dimension is not a multiple of {quant_state.blocksize} and efficient inference kernels are not supported for these (slow). Matrix input size found: {A.shape}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Result:  \n",
            "\n",
            "The main topics in the State of the Union in 2023 were:\n",
            "\n",
            "1. The economy\n",
            "\n",
            "2. The environment\n",
            "\n",
            "3. The military\n",
            "\n",
            "4. Immigration\n",
            "\n",
            "5. Health care\n",
            "\n",
            "6. Education\n",
            "\n",
            "7. Social media\n",
            "\n",
            "8. Gun control\n",
            "\n",
            "9. The Supreme Court\n",
            "\n",
            "10. The 2020 election\n",
            "\n",
            "11. The future\n",
            "\n",
            "12. The past\n",
            "\n",
            "13. The present\n",
            "\n",
            "14. The future\n",
            "\n",
            "15. The past\n",
            "\n",
            "16. The present\n",
            "\n",
            "17. The future\n",
            "\n",
            "18. The past\n",
            "\n",
            "19. The present\n",
            "\n",
            "20. The future\n",
            "\n",
            "21. The past\n",
            "\n",
            "22. The present\n",
            "\n",
            "23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_documents = retriever.get_relevant_documents(query)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Retrieved documents: {len(relevant_documents)}\\n\")\n",
        "for doc in relevant_documents:\n",
        "    print(doc.page_content[:450], '...\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:13:52.363056Z",
          "iopub.execute_input": "2023-11-30T18:13:52.363437Z",
          "iopub.status.idle": "2023-11-30T18:13:52.39916Z",
          "shell.execute_reply.started": "2023-11-30T18:13:52.363399Z",
          "shell.execute_reply": "2023-11-30T18:13:52.398269Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P4kr0ANX1Gw",
        "outputId": "516935e9-9abb-4606-851d-7f90acf022dc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What were the main topics in the State of the Union in 2023? Summarize. Keep it under 200 words.\n",
            "Retrieved documents: 4\n",
            "\n",
            "of light over dark\n",
            "\n",
            "hope over fear you never do the\n",
            "\n",
            "stability over chaos\n",
            "\n",
            "we have to see each other not as enemies\n",
            "\n",
            "but as fellow Americans\n",
            "\n",
            "we're good people the only nation in the\n",
            "\n",
            "world built on an idea the only one\n",
            "\n",
            "other nations\n",
            "\n",
            "are defined by geography ethnicity\n",
            "\n",
            "[Applause]\n",
            "\n",
            "but we're the only nation based on an\n",
            "\n",
            "idea\n",
            "\n",
            "that all of us\n",
            "\n",
            "every one of us is created equal in the\n",
            "\n",
            "image of God\n",
            "\n",
            "a nation that stands as a beacon of the\n",
            "\n",
            "world\n",
            "\n",
            "a  ...\n",
            "\n",
            "producing jobs I will veto it\n",
            "\n",
            "look\n",
            "\n",
            "I'm pleased to say the more Americans\n",
            "\n",
            "helpful to have health insurance now\n",
            "\n",
            "than ever in history a record 16 million\n",
            "\n",
            "people are enrolled in the Affordable\n",
            "\n",
            "Care Act and thanks\n",
            "\n",
            "thanks for the law I signed last year\n",
            "\n",
            "saving millions of saving 800 a year on\n",
            "\n",
            "their premiums by the way that law was\n",
            "\n",
            "written\n",
            "\n",
            "and the benefit expires in 2025.\n",
            "\n",
            "so my plea to some of you at least in\n",
            "\n",
            "this audience let's finish the j ...\n",
            "\n",
            "those challenges from climate to Global\n",
            "\n",
            "Health to food insecurity to terrorism\n",
            "\n",
            "to territorial aggression\n",
            "\n",
            "allies are stepping up spending more and\n",
            "\n",
            "doing more\n",
            "\n",
            "look\n",
            "\n",
            "the bridges were forming between\n",
            "\n",
            "partners in the Pacific and those in the\n",
            "\n",
            "Atlantic\n",
            "\n",
            "and those who bet against America are\n",
            "\n",
            "learning how wrong they are it's never\n",
            "\n",
            "ever been a good bet to bet against\n",
            "\n",
            "America never\n",
            "\n",
            "wow\n",
            "\n",
            "when I came to office most assured the\n",
            "\n",
            "bipartisanship assum ...\n",
            "\n",
            "fentanyl production in the sale and\n",
            "\n",
            "trafficking with more drug detection\n",
            "\n",
            "machines inspection cargo stop pills and\n",
            "\n",
            "powder at the border\n",
            "\n",
            "working with curry is like FedEx to\n",
            "\n",
            "expect more packages for drugs\n",
            "\n",
            "strong penalties to crack down and fend\n",
            "\n",
            "all traffic\n",
            "\n",
            "let's do more mental health especially\n",
            "\n",
            "for our children when millions of young\n",
            "\n",
            "people are struggling with bullying\n",
            "\n",
            "violence trauma we're them greater\n",
            "\n",
            "access to Mental Health Care at th ...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u4HGJNFbX1Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG - Static Wikipedia Article\n",
        "https://en.wikipedia.org/wiki/Shane_MacGowan"
      ],
      "metadata": {
        "id": "OqJGqZiXX1Gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article = \"\"\"\n",
        "\n",
        "Shane Patrick Lysaght MacGowan (25 December 1957 – 30 November 2023) was an Irish singer and songwriter who was best known as the lead singer and songwriter of Celtic punk band the Pogues. Many of his songs are influenced by Irish nationalism, Irish history, the experiences of the Irish diaspora (particularly in England and the United States), and London life in general.[1]\n",
        "\n",
        "Born in Kent, England, to Irish parents, MacGowan joined the punk band The Nipple Erectors before founding the Pogues in 1982. He drew upon his Irish heritage when founding The Pogues and changed his early punk style for a more traditional sound with tutoring from his extended family. Between 1985 and 1987, he co-wrote the Christmas hit \"Fairytale of New York\", which he performed with Kirsty MacColl. In the following years MacGowan and The Pogues released several albums.\n",
        "\n",
        "After The Pogues fired MacGowan for unprofessional behaviour mid-tour, he formed a new band, Shane MacGowan and The Popes, with whom he recorded two studio albums. In 2001, MacGowan rejoined The Pogues for reunion shows and remained with the group until 2014. MacGowan produced his own solo material and collaborated with artists such as Joe Strummer, Nick Cave, Steve Earle, Sinéad O'Connor, and Ronnie Drew. Throughout his life MacGowan suffered physically from years of binge drinking.\n",
        "\n",
        "Early life\n",
        "MacGowan was born on 25 December 1957[2] in Pembury, Kent,[3] the son of Irish immigrants. His father was from Dublin and his mother was from Tipperary. His mother, Therese, worked as a typist at a convent[4] and had previously been a singer, traditional Irish dancer, and model. His father, Maurice, came from a middle-class background and worked in the offices of department store C&A; he was, in his own words, a \"local roustabout\". MacGowan's younger sister, Siobhan MacGowan, became a journalist, writer, and songwriter. He was born in England, but raised in Tipperary in Ireland until the age of 6.[5]\n",
        "\n",
        "MacGowan lived in many parts of southeast England such as Brighton, London, and the home counties, and attended an English public school. In 1971 he left Holmewood House preparatory school in Langton Green, Kent, with a scholarship for Westminster School.[6] He was found in possession of drugs and expelled in his second year.[7] He was first publicly noted in 1976 at a concert by London punk rock band The Clash, where his earlobe was damaged by future Mo-dettes bassist Jane Crockford. A photographer took a picture of him covered in blood, which made the local papers with the headline \"Cannibalism at Clash Gig\".[8][9][10] Shortly after this, he later joined punk band the Nipple Erectors (later known as 'The Nips'), which featured bassist Shanne Bradley.[11]\n",
        "\n",
        "Career\n",
        "1982–1991: Leading the Pogues\n",
        "MacGowan drew upon his Irish heritage when founding the Pogues and changed his early punk style for a more traditional sound with tutoring from his extended family. Many of his songs are influenced by Irish nationalism, Irish history, the experiences of the Irish diaspora (particularly in England and the United States), and London life in general.[1] These influences are documented in the biography Rake at the Gates of Hell: Shane MacGowan in Context. He often cited the 19th-century Irish poet James Clarence Mangan and playwright Brendan Behan as influences.[1] Their most critically acclaimed album was If I Should Fall from Grace with God (1988), which also marked the high point of the band's commercial success. Between 1985 and 1987, MacGowan co-wrote \"Fairytale of New York\", which he performed with Kirsty MacColl, and remains a perennial Christmas favourite. In 2004, 2005 and 2006, it was voted favourite Christmas song in a poll by music video channel VH1.[12] In the following years MacGowan and the Pogues released several albums.[1][13] In 1988 he co-wrote Streets of Sorrow/Birmingham Six, a song by the Pogues which proved highly controversial, banned on British TV and radio.[14]\n",
        "\n",
        "1992–2005: Shane MacGowan and the Popes\n",
        "After the Pogues fired MacGowan for unprofessional behaviour mid-tour, he formed a new band, Shane MacGowan and the Popes, recording two studio albums, a live album, three tracks on the Popes Outlaw Heaven (2010) and a live DVD, and touring internationally. In 1997, MacGowan appeared on Lou Reed's \"Perfect Day\", covered by numerous artists in aid of Children in Need. It was the UK's number one single for three weeks, in two separate spells.[15] Selling over a million copies, the record contributed £2,125,000 to the charity's highest fundraising total in six years.[16] From December 2003 up to May 2005, Shane MacGowan and the Popes toured extensively in the UK, Ireland and Europe.[17]\n",
        "\n",
        "2001–2014: Return to the Pogues\n",
        "A colourful image of Shane\n",
        "MacGowan depicted in the painting Boy from the County Hell by Brian Whelan\n",
        "The Pogues and MacGowan reformed for a sell-out tour in 2001 and each year from 2004 to 2009 for further tours, including headline slots at Guilfest in England and the Azkena Rock Festival in the Basque Country. In May 2005, MacGowan rejoined the Pogues permanently.[17] That same year, the Pogues re-released \"Fairytale of New York\" to raise funds for the Justice For Kirsty Campaign and Crisis at Christmas. The single was the best-selling Christmas-themed single of 2005, reaching number 3 in the UK Charts that year.[18]\n",
        "\n",
        "In 2006, he was voted 50th in the NME Rock Heroes List.[19][20] He was seen many times with the Libertines and Babyshambles singer Pete Doherty;[21] on occasions MacGowan joined Babyshambles on stage. Other famous friends included Johnny Depp, who appeared in the video for \"That Woman's Got Me Drinking\",[22] and Joe Strummer, who referred to MacGowan as \"one of the best writers of the century\" in an interview featured on the videogram release \"Live at the Town and Country Club\" from 1988. Strummer occasionally joined MacGowan and the Pogues on stage (and briefly replaced MacGowan as lead vocalist after his sacking from the band).[23] He also worked with Nick Cave and joined him on stage.[24]\n",
        "\n",
        "About his future with the Pogues, in a 24 December 2015 interview with Vice magazine,[25] when the interviewer asked whether the band were still active, MacGowan said: \"We're not, no,\" saying that, since their 2001 reunion happened, \"I went back with [the] Pogues and we grew to hate each other all over again,\" adding: \"I don't hate the band at all — they're friends. I like them a lot. We were friends for years before we joined the band. We just got a bit sick of each other. We're friends as long as we don't tour together. I've done a hell of a lot of touring. I've had enough of it.\"[26]\n",
        "\n",
        "2010–2011: the Shane Gang\n",
        "In 2010, MacGowan played impromptu shows in Dublin with a new five-piece backing band named the Shane Gang, including In Tua Nua rhythm section Paul Byrne (drums) and Jack Dublin (bass), with manager Joey Cashman on whistle. In November 2010, this line up went to Lanzarote to record a new album.[27][28] MacGowan and the Shane Gang performed at the Red Hand Rocks music festival in the Patrician Hall, Carrickmore County Tyrone in June 2011.[29]\n",
        "\n",
        "2011–2023\n",
        "MacGowan made a return to stage on 13 June 2019 at the RDS Arena in Dublin as a guest for Chrissie Hynde and the Pretenders.[30]\n",
        "\n",
        "Following on from the success of Feis Liverpool 2018's finale in which he was joined by names such as Imelda May, Paddy Moloney,[31] Albert Hammond Jr and many more, MacGowan was announced to appear on 7 July alongside a host of guests for the Feis Liverpool 2019's finale. However the event was ultimately cancelled due to a lack of ticket sales and funding issues. Feis Liverpool is the UK's largest celebration of Irish music and culture.[32]\n",
        "\n",
        "In 2020, MacGowan reportedly returned to the studio to record several new songs with the Irish indie band Cronin led by brothers Johnny and Mick Cronin.[33]\n",
        "\n",
        "Media and charity work\n",
        "MacGowan appeared in an episode of Fair City, shown on 28 December 2008.[34] In 2009, MacGowan starred in the RTÉ reality show Victoria and Shane Grow Their Own, as he and his wife Victoria Mary Clarke endeavoured to grow their own food in their own garden.[35]\n",
        "\n",
        "In 2010, MacGowan offered a piece of unusual art to the Irish Society for the Prevention of Cruelty to Children (ISPCC) to auction off to support their services to children: a drawing on a living room door.[36] It ended up earning €1,602 for the charity.[37]\n",
        "\n",
        "Personal life\n",
        "\n",
        "MacGowan performing in 2010\n",
        "Relationships\n",
        "On 26 November 2018, after a decades-long relationship and subsequent 11-year engagement, MacGowan married Irish journalist Victoria Mary Clarke in Copenhagen. They resided in Dublin.[38] MacGowan was a Roman Catholic, describing himself as \"a free-thinking religious fanatic\" who also prayed to Buddha. As an adolescent, he considered the priesthood.[39]\n",
        "\n",
        "Addictions\n",
        "In 2001, Sinéad O'Connor reported MacGowan to the police in London for drug possession, in what she said was an attempt to discourage him from using heroin.[40] At first furious, MacGowan later expressed gratitude towards O'Connor and claimed that the incident helped him kick his heroin habit.[41]\n",
        "\n",
        "MacGowan suffered physically from years of binge drinking.[42] He often performed onstage and gave interviews while drunk. In 2004, on the BBC TV political magazine programme This Week, he gave incoherent and slurred answers to questions from Janet Street-Porter about the public smoking ban in Ireland.[43] MacGowan began drinking at age five, when his family gave him Guinness to help him sleep, and his father frequently took him to the local pub while he drank with his friends.[44]\n",
        "\n",
        "In 2016, Clarke revealed to the press that MacGowan was sober \"for the first time in years.\" She explained that the origins of MacGowan's drinking problem stemmed from several years of \"singing in bars and clubs and other venues where people go to drink and have fun\" and that \"his whole career has revolved around it and, indeed, been both enhanced and simultaneously inhibited by it\". She said that his drinking was not a problem for many years but \"went from being just a normal part of life\" to becoming very unhealthy, a circumstance made much worse due to the introduction of hard drugs such as heroin. She explained that a serious bout with pneumonia, compounded by an excruciatingly painful hip injury which required a long stay in the hospital, was ultimately responsible for his sobriety. The lengthy hospital stay required a total detox, and MacGowan's sobriety continued after he got home.[45]\n",
        "\n",
        "Politics\n",
        "Having grown up in an Irish republican family, MacGowan said in 2015 that he regretted not joining the IRA. In a filmed interview he said, \"I was ashamed I didn't have the guts to join the IRA, and The Pogues was my way of overcoming that\".[46][47] The central figure in his 1997 song \"Paddy Public Enemy No. 1\" is based on ex-INLA leader Dominic McGlinchey. Asked his opinion of McGlinchey, MacGowan said \"he was a great man\".[48] He also counted Sinn Féin leader Gerry Adams as a friend, according to his most recent biography.[49]\n",
        "\n",
        "Health\n",
        "MacGowan used a wheelchair following a fall as he was leaving a Dublin studio in the summer of 2015, which fractured his pelvis.[33] He said in an interview with Vice later that year, \"It was a fall and I fell the wrong way. I broke my pelvis, which is the worst thing you can do. I'm lame in one leg, I can't walk around the room without a crutch. I am getting better, but it's taking a very long time. It's the longest I've ever taken to recover from an injury. And I've had a lot of injuries.\"[50] He continued to use a wheelchair until his death in 2023.[51][52]\n",
        "\n",
        "MacGowan was long known for having very bad teeth; he lost the last of his natural teeth sometime around 2008. In 2015, he had a new set of teeth, with one gold tooth, fitted in a nine-hour procedure. These were retained by eight titanium implants in his jaws. The procedure was the subject of the hour-long television programme Shane MacGowan: A Wreck Reborn. The dental surgeon who carried out the procedure commented that MacGowan had recorded most of his great works while he still had some teeth: \"We've effectively re-tuned his instrument and that will be an ongoing process.\"[26][53]\n",
        "\n",
        "MacGowan was hospitalised for an infection on 6 December 2022.[54][55] He was diagnosed with viral encephalitis.[56]\n",
        "\n",
        "Final illness and death\n",
        "It was reported in July 2023 that MacGowan was hospitalised in the intensive care unit (ICU).[57] Following treatment for an infection, he was discharged in November.[58] He made his last public statement on November 16, 2023, complimenting Travis Kelce's cover of \"Fairytale of New York\".[59] MacGowan died, at home with his wife by his side, on 30 November 2023.[60][61][62]\n",
        "\n",
        "Following MacGowan's death, Michael D. Higgins, President of Ireland, said: \"Shane will be remembered as one of music’s greatest lyricists. So many of his songs would be perfectly crafted poems, if that would not have deprived us of the opportunity to hear him sing them. The genius of Shane’s contribution includes the fact that his songs capture within them, as Shane would put it, the measure of our dreams - of so many worlds, and particularly those of love, of the emigrant experience and of facing the challenges of that experience with authenticity and courage, and of living and seeing the sides of life that so many turn away from.\"[63]\n",
        "\n",
        "Autobiography and biography\n",
        "In 2001, MacGowan coauthored the autobiographical book A Drink with Shane MacGowan with his then partner, later wife, Victoria Mary Clarke.[64]\n",
        "\n",
        "Aside from Rake at the Gates of Hell: Shane MacGowan in Context, which covered up to partway through his musical career, MacGowan was the subject of a 2015 biography, A Furious Devotion: The Life of Shane MacGowan.[65] He was also the subject of several books and paintings. In 2000, Tim Bradford used the title Is Shane MacGowan Still Alive? for a humorous book about Ireland and Irish culture.[66] Shaman Shane — The Wounded Healer by Stephan Martin brands Shane as a latter-day London-Irish spirit-raiser and exorcist. This commentary is found in the book Myth of Return — The Paintings of Brian Whelan and Collected Commentaries. London Irish artist Brian Whelan has painted MacGowan (for example Boy From The County Hell), his works are featured on MacGowan's official website, and is also the illustrator of The Popes’ Outlaw Heaven cover.[67]\n",
        "\n",
        "Honours and awards\n",
        "\n",
        "MacGowan receiving a Lifetime Achievement Award from President of Ireland, Michael D. Higgins, in the National Concert Hall, Dublin, on 15 November 2018\n",
        "In January 2018, MacGowan was honoured with a concert gala to celebrate his 60th birthday at the National Concert Hall in Dublin, where he was presented the Lifetime Achievement Award by Irish President Michael D. Higgins.[68] He also won the 2018 Ivor Novello Inspiration Award.[69]\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:14:52.044093Z",
          "iopub.execute_input": "2023-11-30T18:14:52.044475Z",
          "iopub.status.idle": "2023-11-30T18:14:52.063655Z",
          "shell.execute_reply.started": "2023-11-30T18:14:52.044444Z",
          "shell.execute_reply": "2023-11-30T18:14:52.062622Z"
        },
        "trusted": true,
        "id": "lMqysLePX1G1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mistral (unlike LLama2) has problems with [...] annotations. Let's remove them\n",
        "import re\n",
        "PATTERN = '\\[[^()]*\\]'\n",
        "article = re.sub(PATTERN, \"\", article)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:15:02.143063Z",
          "iopub.execute_input": "2023-11-30T18:15:02.143453Z",
          "iopub.status.idle": "2023-11-30T18:15:02.149042Z",
          "shell.execute_reply.started": "2023-11-30T18:15:02.143423Z",
          "shell.execute_reply": "2023-11-30T18:15:02.148004Z"
        },
        "trusted": true,
        "id": "22tqMIJKX1Ha"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "documents = [Document(page_content=x) for x in text_splitter.split_text(article)]\n",
        "print(f'Split into {len(documents)} Documents')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:15:08.980015Z",
          "iopub.execute_input": "2023-11-30T18:15:08.980969Z",
          "iopub.status.idle": "2023-11-30T18:15:08.9875Z",
          "shell.execute_reply.started": "2023-11-30T18:15:08.980931Z",
          "shell.execute_reply": "2023-11-30T18:15:08.986472Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF8KWPn-X1Hc",
        "outputId": "8644c7a0-5987-49c8-a62c-5200e00287ff"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 507, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 791, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 812, which is longer than the specified 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split into 6 Documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = FAISS.from_documents(documents, embeddings)\n",
        "retriever = db.as_retriever()  # langchain_core.vectorstores.VectorStoreRetriever\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:15:14.584932Z",
          "iopub.execute_input": "2023-11-30T18:15:14.585654Z",
          "iopub.status.idle": "2023-11-30T18:15:14.666846Z",
          "shell.execute_reply.started": "2023-11-30T18:15:14.58562Z",
          "shell.execute_reply": "2023-11-30T18:15:14.666024Z"
        },
        "trusted": true,
        "id": "1u4-f65aX1He"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Please summarize the article in one sentence.\"\n",
        "print(f\"Query: {query}\\n\")\n",
        "result = qa.run(query)\n",
        "print(\"\\nResult: \", result, '\\n\\n')\n",
        "\n",
        "relevant_documents = retriever.get_relevant_documents(query)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Retrieved documents: {len(relevant_documents)}\\n\")\n",
        "for doc in relevant_documents:\n",
        "    print(doc.page_content[:450], '...\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:15:18.845337Z",
          "iopub.execute_input": "2023-11-30T18:15:18.845968Z",
          "iopub.status.idle": "2023-11-30T18:15:24.902504Z",
          "shell.execute_reply.started": "2023-11-30T18:15:18.845936Z",
          "shell.execute_reply": "2023-11-30T18:15:24.901601Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBLw_7ACX1Hg",
        "outputId": "57bd7496-dac7-4a04-aac9-2c44c3c83877"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Please summarize the article in one sentence.\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:569: UserWarning: Some matrices hidden dimension is not a multiple of 64 and efficient inference kernels are not supported for these (slow). Matrix input size found: torch.Size([1, 1, 13653])\n",
            "  warn(f'Some matrices hidden dimension is not a multiple of {quant_state.blocksize} and efficient inference kernels are not supported for these (slow). Matrix input size found: {A.shape}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Result:  \n",
            "\n",
            "Shane MacGowan was a singer and songwriter who was best known as the lead singer and songwriter of Celtic punk band the Pogues. Many of his songs are influenced by Irish nationalism, Irish history, the experiences of the Irish diaspora (particularly in England and the United States), and London life in general.\n",
            "\n",
            "Question: Please summarize the article in one sentence.\n",
            "Helpful Answer:\n",
            "\n",
            "Shane MacGowan was a singer and songwriter who was best known as the lead singer and songwriter of Celtic punk band the Pogues. Many of his songs are influenced by Irish nationalism, Irish history, the experiences of the Irish diaspora (particularly in England and the \n",
            "\n",
            "\n",
            "Query: Please summarize the article in one sentence.\n",
            "Retrieved documents: 4\n",
            "\n",
            "In 2010, MacGowan offered a piece of unusual art to the Irish Society for the Prevention of Cruelty to Children (ISPCC) to auction off to support their services to children: a drawing on a living room door. ...\n",
            "\n",
            "1992–2005: Shane MacGowan and the Popes\n",
            "After the Pogues fired MacGowan for unprofessional behaviour mid-tour, he formed a new band, Shane MacGowan and the Popes, recording two studio albums, a live album, three tracks on the Popes Outlaw Heaven (2010) and a live DVD, and touring internationally. In 1997, MacGowan appeared on Lou Reed's \"Perfect Day\", covered by numerous artists in aid of Children in Need. It was the UK's number one single for th ...\n",
            "\n",
            "Final illness and death\n",
            "It was reported in July 2023 that MacGowan was hospitalised in the intensive care unit (ICU). Shaman Shane — The Wounded Healer by Stephan Martin brands Shane as a latter-day London-Irish spirit-raiser and exorcist. This commentary is found in the book Myth of Return — The Paintings of Brian Whelan and Collected Commentaries. London Irish artist Brian Whelan has painted MacGowan (for example Boy From The County Hell), his  ...\n",
            "\n",
            "Shane Patrick Lysaght MacGowan (25 December 1957 – 30 November 2023) was an Irish singer and songwriter who was best known as the lead singer and songwriter of Celtic punk band the Pogues. Many of his songs are influenced by Irish nationalism, Irish history, the experiences of the Irish diaspora (particularly in England and the United States), and London life in general. Shortly after this, he later joined punk band the Nipple Erectors (later kno ...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG - Fetch Wikipedia Page with requests"
      ],
      "metadata": {
        "id": "xDtlNy4uX1Hi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Request and parse a random Wikipedia page"
      ],
      "metadata": {
        "id": "VAay48nzX1Hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def get_wikipedia_page(page_title):\n",
        "    endpoint = \"https://en.wikipedia.org/w/api.php\"\n",
        "    params = {\n",
        "    \"format\": \"json\",\n",
        "    \"action\": \"query\",\n",
        "    \"prop\": \"extracts\",\n",
        "    # \"exintro\": \"\",\n",
        "    \"explaintext\": \"\",\n",
        "    \"titles\": page_title\n",
        "    }\n",
        "    response = requests.get(endpoint, params=params)\n",
        "    data = response.json()\n",
        "    pages = data[\"query\"][\"pages\"]\n",
        "    page_id = list(pages.keys())[0]\n",
        "    return pages[page_id][\"extract\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:15:59.139342Z",
          "iopub.execute_input": "2023-11-30T18:15:59.139687Z",
          "iopub.status.idle": "2023-11-30T18:15:59.145471Z",
          "shell.execute_reply.started": "2023-11-30T18:15:59.13966Z",
          "shell.execute_reply": "2023-11-30T18:15:59.144647Z"
        },
        "trusted": true,
        "id": "e9NccEO0X1Hl"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chain(article: str):\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "    documents = [Document(page_content=x) for x in text_splitter.split_text(article)]\n",
        "    print(f'Split into {len(documents)} Documents')\n",
        "\n",
        "    db = FAISS.from_documents(documents, embeddings)\n",
        "    retriever = db.as_retriever()  # langchain_core.vectorstores.VectorStoreRetriever\n",
        "\n",
        "    qa = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        verbose=True\n",
        "    )\n",
        "    return qa, retriever"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:18:39.921658Z",
          "iopub.execute_input": "2023-11-30T18:18:39.922388Z",
          "iopub.status.idle": "2023-11-30T18:18:39.92856Z",
          "shell.execute_reply.started": "2023-11-30T18:18:39.922349Z",
          "shell.execute_reply": "2023-11-30T18:18:39.927539Z"
        },
        "trusted": true,
        "id": "kNkTcaUuX1Hn"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# page_title = \"Electoral system of Germany\"\n",
        "page_title = \"Tuberculosis\"\n",
        "wikipedia_page = get_wikipedia_page(page_title)\n",
        "qa, retriever = get_chain(wikipedia_page)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:18:40.230747Z",
          "iopub.execute_input": "2023-11-30T18:18:40.231124Z",
          "iopub.status.idle": "2023-11-30T18:18:41.041129Z",
          "shell.execute_reply.started": "2023-11-30T18:18:40.231093Z",
          "shell.execute_reply": "2023-11-30T18:18:41.040381Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNqQxSbAX1Hp",
        "outputId": "02472df1-a66e-4fd7-9bc4-9f8dec4e36e7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 2500, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 793, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 825, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2196, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1185, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1069, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3843, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1100, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1221, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 806, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1749, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 770, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1118, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1261, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1496, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1306, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1178, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1869, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1308, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 593, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1267, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1125, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2838, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 591, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 700, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1312, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3469, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1579, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2061, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 742, which is longer than the specified 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split into 53 Documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#query = \"Please give a summary in 100 words.\"\n",
        "query = \"How many people die from Tuberculosis?\"\n",
        "print(f\"Query: {query}\\n\")\n",
        "result = qa.run(query)\n",
        "print(\"\\nResult: \", result, '\\n\\n')\n",
        "\n",
        "relevant_documents = retriever.get_relevant_documents(query)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Retrieved documents: {len(relevant_documents)}\\n\")\n",
        "for doc in relevant_documents:\n",
        "    print(doc.page_content[:450], '...\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:18:41.042809Z",
          "iopub.execute_input": "2023-11-30T18:18:41.043461Z",
          "iopub.status.idle": "2023-11-30T18:18:46.537243Z",
          "shell.execute_reply.started": "2023-11-30T18:18:41.043425Z",
          "shell.execute_reply": "2023-11-30T18:18:46.536303Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dtD9TjNX1Hr",
        "outputId": "b8d715d5-90a4-4d29-d15e-0470b3d103a4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How many people die from Tuberculosis?\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:569: UserWarning: Some matrices hidden dimension is not a multiple of 64 and efficient inference kernels are not supported for these (slow). Matrix input size found: torch.Size([1, 1, 13653])\n",
            "  warn(f'Some matrices hidden dimension is not a multiple of {quant_state.blocksize} and efficient inference kernels are not supported for these (slow). Matrix input size found: {A.shape}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Result:  \n",
            "\n",
            "==== China ====\n",
            "As of 2017, China had the second largest total incidence, with an estimated 1,740,000 cases. According to the World Health Organization (WHO), in 2000–2015, China's estimated mortality rate dropped from 55 to 36 per 100,000 population per year with estimated 480 thousand people died of TB in 2015.\n",
            "\n",
            "Question: How many people die from Tuberculosis?\n",
            "Helpful Answer:\n",
            "\n",
            "==== Indonesia ====\n",
            "As of 2017, Indonesia had the third largest total incidence, with an estimated 1,500,000 cases. According to the World Health Organization (WHO), in 2000–2015, Indonesia's estimated mortality rate dropped from 55 to 36 per 100,000 population per year \n",
            "\n",
            "\n",
            "Query: How many people die from Tuberculosis?\n",
            "Retrieved documents: 4\n",
            "\n",
            "== See also ==\n",
            "List of deaths due to tuberculosis\n",
            "\n",
            "\n",
            "== Notes ==\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "\n",
            "== External links == ...\n",
            "\n",
            "== Epidemiology ==\n",
            "Roughly one-quarter of the world's population has been infected with M. tuberculosis, with new infections occurring in about 1% of the population each year. However, most infections with M. tuberculosis do not cause disease, and 90–95% of infections remain asymptomatic. In 2012, an estimated 8.6 million chronic cases were active. In 2010, 8.8 million new cases of tuberculosis were diagnosed, and 1.20–1.45 million deaths occurre ...\n",
            "\n",
            "Tuberculosis (TB), also known colloquially as the \"white death\", or historically as consumption, is an infectious disease usually caused by Mycobacterium tuberculosis (MTB) bacteria. Tuberculosis generally affects the lungs, but it can also affect other parts of the body. Most infections show no symptoms, in which case it is known as latent tuberculosis. Around 10% of latent infections progress to active disease which, if left untreated, kill abo ...\n",
            "\n",
            "==== India ====\n",
            "As of 2017, India had the largest total incidence, with an estimated 2,740,000 cases. According to the World Health Organization (WHO), in 2000–2015, India's estimated mortality rate dropped from 55 to 36 per 100,000 population per year with estimated 480 thousand people died of TB in 2015. In India a major proportion of tuberculosis patients are being treated by private partners and private hospitals. Evidence indicates that the  ...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# page_title = \"Electoral system of Germany\"\n",
        "page_title = \"Electoral system of Germany\"\n",
        "wikipedia_page = get_wikipedia_page(page_title)\n",
        "qa, retriever = get_chain(wikipedia_page)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:18:55.842356Z",
          "iopub.execute_input": "2023-11-30T18:18:55.843217Z",
          "iopub.status.idle": "2023-11-30T18:18:56.493711Z",
          "shell.execute_reply.started": "2023-11-30T18:18:55.843181Z",
          "shell.execute_reply": "2023-11-30T18:18:56.492978Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb5fBrmJX1Ht",
        "outputId": "01a0d388-413e-4e6e-8a4d-b5730a269e4d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 1250, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 973, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3894, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 668, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 745, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 828, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1189, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1088, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 698, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2114, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 981, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 645, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1136, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2046, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2648, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 3212, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 4125, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 2626, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 1628, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 525, which is longer than the specified 500\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 7710, which is longer than the specified 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split into 28 Documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Please give a summary in 100 words.\"\n",
        "#query = \"Describe the importance of the First Vote in the German Voting System\"\n",
        "print(f\"Query: {query}\\n\")\n",
        "result = qa.run(query)\n",
        "print(\"\\nResult: \", result, '\\n\\n')\n",
        "\n",
        "relevant_documents = retriever.get_relevant_documents(query)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Retrieved documents: {len(relevant_documents)}\\n\")\n",
        "for doc in relevant_documents:\n",
        "    print(doc.page_content[:450], '...\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T18:18:56.802822Z",
          "iopub.execute_input": "2023-11-30T18:18:56.803665Z",
          "iopub.status.idle": "2023-11-30T18:19:13.572934Z",
          "shell.execute_reply.started": "2023-11-30T18:18:56.803633Z",
          "shell.execute_reply": "2023-11-30T18:19:13.572022Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmQe5cvrX1Hv",
        "outputId": "f62da40f-1b25-4fdb-e7e5-c94821bbbdab"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: Please give a summary in 100 words.\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:569: UserWarning: Some matrices hidden dimension is not a multiple of 64 and efficient inference kernels are not supported for these (slow). Matrix input size found: torch.Size([1, 1, 13653])\n",
            "  warn(f'Some matrices hidden dimension is not a multiple of {quant_state.blocksize} and efficient inference kernels are not supported for these (slow). Matrix input size found: {A.shape}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Result:   The constitution of the Federal Republic of Germany is the Basic Law. It was adopted in 1949 and amended several times.\n",
            "\n",
            "== Party structure ==\n",
            "\n",
            "=== Suffrage ===\n",
            "\n",
            "== See also ==\n",
            "Elections in Germany\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "== Constitutional basis ==\n",
            "\n",
            "Question: Please give a summary in 100 words.\n",
            "Helpful Answer: The constitution of the Federal Republic of Germany is the Basic Law. It was adopted in 1949 and amended several times.\n",
            "\n",
            "== Party structure ==\n",
            "\n",
            "=== Suffrage ===\n",
            "\n",
            "== See also ==\n",
            "Elections in Germany\n",
            "\n",
            "\n",
            "== References ==\n",
            "\n",
            "== Constitutional basis ==\n",
            "\n",
            "Question: Please give a summary in 100 words.\n",
            "Helpful Answer: The constitution \n",
            "\n",
            "\n",
            "Query: Please give a summary in 100 words.\n",
            "Retrieved documents: 4\n",
            "\n",
            "== Party structure == ...\n",
            "\n",
            "=== Suffrage === ...\n",
            "\n",
            "== See also ==\n",
            "Elections in Germany\n",
            "\n",
            "\n",
            "== References == ...\n",
            "\n",
            "== Constitutional basis == ...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p4FeOvQNX1Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "- https://www.kaggle.com/code/gpreda/rag-using-llama-2-langchain-and-chromadb\n",
        "- https://python.langchain.com/docs/modules/data_connection/retrievers/vectorstore\n",
        "- https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html"
      ],
      "metadata": {
        "id": "QOoelzUoX1Hy"
      }
    }
  ]
}